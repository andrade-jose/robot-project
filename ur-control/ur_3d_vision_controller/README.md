# ü§ñ Vision UR Controller ‚Äì Rob√¥ com Vis√£o 3D

Sistema completo para controle de rob√¥ UR (Universal Robots) utilizando vis√£o 3D com c√¢mera Balmer/RealSense.

---

## üìä Vis√£o Geral

Este sistema integra:

* Captura e processamento de imagens 3D
* Detec√ß√£o de objetos usando redes neurais
* Transforma√ß√£o de coordenadas entre c√¢mera e rob√¥
* Controle preciso do rob√¥ UR via interface RTDE

---

## üîß Componentes Principais

### 1. `DepthCamera`

* Gerencia a c√¢mera RealSense
* Captura frames alinhados (cor + profundidade)
* Converte coordenadas de pixel para 3D

### 2. `ObjectDetector`

* Carrega modelo TensorFlow/Keras
* Detecta objetos em imagens RGB
* Retorna bounding box e posi√ß√£o 3D

### 3. `CoordinateTransformer`

* Converte coordenadas da c√¢mera para o rob√¥
* Usa matriz de calibra√ß√£o
* Calcula orienta√ß√£o do gripper com base na altura

### 4. `URController`

* Controla rob√¥ UR via protocolo RTDE
* Move para poses definidas
* Gera e executa scripts URScript

### 5. `VisionToMotionController`

* Integra todos os componentes acima
* Gerencia ciclos de detec√ß√£o e movimento

---

## ‚öñÔ∏è Requisitos

* Python 3.7+
* Bibliotecas:

  * OpenCV
  * pyrealsense2
  * TensorFlow 2.x
  * ur-rtde
  * NumPy

---

## ‚öôÔ∏è Configura√ß√£o

### 1. Configura√ß√£o da c√¢mera

```python
{
    'width': 640,
    'height': 480,
    'fps': 30
}
```

### 2. Arquivo de calibra√ß√£o (`calibration.json`)

```json
{
  "transformation_matrix": [...],
  "tool_offset": [0, 0, 0]
}
```

---

## ‚ñ∂Ô∏è Uso B√°sico

```python
# Inicializa√ß√£o
de vision_to_motion_controller import VisionToMotionController

system = VisionToMotionController(
    camera_config=CONFIG['camera'],
    model_path='object_detector.h5',
    calibration_file='calibration.json',
    robot_ip='192.168.1.10'
)

try:
    while True:
        success = system.run_single_cycle()
        print("Sucesso" if success else "Sem detec√ß√£o")
        time.sleep(1)
except KeyboardInterrupt:
    print("Parando sistema...")
finally:
    system.shutdown()
```

---

## ‚öñÔ∏è Fluxo de Opera√ß√£o

1. Captura de frames alinhados (cor + profundidade)
2. Detec√ß√£o de objeto principal
3. Convers√£o para coordenadas do rob√¥
4. C√°lculo das poses: aproxima√ß√£o, alvo, retirada
5. Gera√ß√£o e execu√ß√£o do script de movimento

---

## üîÑ Personaliza√ß√£o

* **Modelo de detec√ß√£o**: Substitua `object_detector.h5` pelo seu pr√≥prio
* **Par√¢metros de movimento**: Altere velocidades no `URController`
* **Estrat√©gia de abordagem**: Modifique `calculate_gripper_orientation`

---

## ‚ö†Ô∏è Limita√ß√µes

* Exige calibra√ß√£o precisa c√¢mera ‚Üî rob√¥
* Modelo de detec√ß√£o deve ser previamente treinado
* Velocidade segura por padr√£o (ajust√°vel)

---

## üìà Melhorias Futuras

* Rastreamento de objeto entre ciclos
* Verifica√ß√£o de colis√£o
* Feedback de for√ßa no pick
* Suporte a m√∫ltiplos objetos

---

## üîó Refer√™ncias

* [Intel RealSense SDK](https://www.intelrealsense.com/sdk-2/)
* [UR RTDE Guide](https://www.universal-robots.com/articles/ur/interface-communication/real-time-data-exchange-rtde-guide/)
* [TensorFlow Keras Docs](https://www.tensorflow.org/guide/keras)
